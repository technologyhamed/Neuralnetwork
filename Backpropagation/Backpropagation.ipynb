{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "/Backpropagation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSrM0dUn2WttfihLm0iTR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/technologyhamed/Neuralnetwork/blob/Single/Backpropagation/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fOFIJL_qBKIW",
        "outputId": "d8e5970a-d32f-4eb3-aa15-90bfa8f36d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.291027774\n",
            "1 0.283547133\n",
            "2 0.275943289\n",
            "3 0.268232761\n",
            "4 0.260434393\n",
            "5 0.252569176\n",
            "6 0.244659999\n",
            "7 0.236731316\n",
            "8 0.228808741\n",
            "9 0.220918592\n",
            "10 0.213087389\n",
            "11 0.205341328\n",
            "12 0.197705769\n",
            "13 0.190204742\n",
            "14 0.182860503\n",
            "15 0.175693166\n",
            "16 0.168720403\n",
            "17 0.16195725\n",
            "18 0.155415989\n",
            "19 0.149106135\n",
            "20 0.14303449\n",
            "21 0.137205276\n",
            "22 0.131620316\n",
            "23 0.126279262\n",
            "24 0.121179847\n",
            "25 0.116318143\n",
            "26 0.111688831\n",
            "27 0.107285459\n",
            "28 0.103100677\n",
            "29 0.099126464\n",
            "30 0.095354325\n",
            "31 0.091775464\n",
            "32 0.088380932\n",
            "33 0.085161757\n",
            "34 0.082109043\n",
            "35 0.079214055\n",
            "36 0.076468284\n",
            "37 0.073863495\n",
            "38 0.071391768\n",
            "39 0.069045516\n",
            "40 0.066817506\n",
            "41 0.064700863\n",
            "42 0.062689072\n",
            "43 0.060775976\n",
            "44 0.058955766\n",
            "45 0.057222975\n",
            "46 0.05557246\n",
            "47 0.053999393\n",
            "48 0.052499243\n",
            "49 0.051067764\n",
            "50 0.049700977\n",
            "51 0.048395156\n",
            "52 0.047146814\n",
            "53 0.045952686\n",
            "54 0.044809717\n",
            "55 0.043715048\n",
            "56 0.042666004\n",
            "57 0.041660079\n",
            "58 0.040694928\n",
            "59 0.039768356\n",
            "60 0.038878306\n",
            "61 0.03802285\n",
            "62 0.037200182\n",
            "63 0.036408606\n",
            "64 0.035646534\n",
            "65 0.034912472\n",
            "66 0.03420502\n",
            "67 0.033522862\n",
            "68 0.032864759\n",
            "69 0.032229549\n",
            "70 0.031616135\n",
            "71 0.031023487\n",
            "72 0.030450633\n",
            "73 0.029896659\n",
            "74 0.0293607\n",
            "75 0.028841943\n",
            "76 0.028339618\n",
            "77 0.027852999\n",
            "78 0.0273814\n",
            "79 0.026924172\n",
            "80 0.026480701\n",
            "81 0.026050405\n",
            "82 0.025632734\n",
            "83 0.025227167\n",
            "84 0.024833208\n",
            "85 0.024450388\n",
            "86 0.024078263\n",
            "87 0.023716408\n",
            "88 0.023364423\n",
            "89 0.023021926\n",
            "90 0.022688552\n",
            "91 0.022363958\n",
            "92 0.022047812\n",
            "93 0.021739804\n",
            "94 0.021439633\n",
            "95 0.021147015\n",
            "96 0.020861679\n",
            "97 0.020583365\n",
            "98 0.020311827\n",
            "99 0.020046828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#\n",
        "# Shorthand:\n",
        "#   \"pd_\" as a variable prefix means \"partial derivative\"\n",
        "#   \"d_\" as a variable prefix means \"derivative\"\n",
        "#   \"_wrt_\" is shorthand for \"with respect to\"\n",
        "#   \"w_ho\" and \"w_ih\" are the index of weights from hidden to output layer neurons and input to hidden layer neurons respectively\n",
        "#\n",
        "# Comment references:\n",
        "#\n",
        "# [1] Wikipedia article on Backpropagation\n",
        "#   http://en.wikipedia.org/wiki/Backpropagation#Finding_the_derivative_of_the_error\n",
        "# [2] Neural Networks for Machine Learning course on Coursera by Geoffrey Hinton\n",
        "#   https://class.coursera.org/neuralnets-2012-001/lecture/39\n",
        "# [3] The Back Propagation Algorithm\n",
        "#   https://www4.rgu.ac.uk/files/chapter3%20-%20bp.pdf\n",
        "Error=[]\n",
        "class NeuralNetwork:\n",
        "    LEARNING_RATE = 0.5\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs, hidden_layer_weights = None, hidden_layer_bias = None, output_layer_weights = None, output_layer_bias = None):\n",
        "        self.num_inputs = num_inputs\n",
        "\n",
        "        self.hidden_layer = NeuronLayer(num_hidden, hidden_layer_bias)\n",
        "        self.output_layer = NeuronLayer(num_outputs, output_layer_bias)\n",
        "\n",
        "        self.init_weights_from_inputs_to_hidden_layer_neurons(hidden_layer_weights)\n",
        "        self.init_weights_from_hidden_layer_neurons_to_output_layer_neurons(output_layer_weights)\n",
        "\n",
        "    def init_weights_from_inputs_to_hidden_layer_neurons(self, hidden_layer_weights):\n",
        "        weight_num = 0\n",
        "        for h in range(len(self.hidden_layer.neurons)):\n",
        "            for i in range(self.num_inputs):\n",
        "                if not hidden_layer_weights:\n",
        "                    self.hidden_layer.neurons[h].weights.append(random.random())\n",
        "                else:\n",
        "                    self.hidden_layer.neurons[h].weights.append(hidden_layer_weights[weight_num])\n",
        "                weight_num += 1\n",
        "\n",
        "    def init_weights_from_hidden_layer_neurons_to_output_layer_neurons(self, output_layer_weights):\n",
        "        weight_num = 0\n",
        "        for o in range(len(self.output_layer.neurons)):\n",
        "            for h in range(len(self.hidden_layer.neurons)):\n",
        "                if not output_layer_weights:\n",
        "                    self.output_layer.neurons[o].weights.append(random.random())\n",
        "                else:\n",
        "                    self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num])\n",
        "                weight_num += 1\n",
        "\n",
        "    def inspect(self):\n",
        "        print('------')\n",
        "        print('* Inputs: {}'.format(self.num_inputs))\n",
        "        print('------')\n",
        "        print('Hidden Layer')\n",
        "        self.hidden_layer.inspect()\n",
        "        print('------')\n",
        "        print('* Output Layer')\n",
        "        self.output_layer.inspect()\n",
        "        print('------')\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        hidden_layer_outputs = self.hidden_layer.feed_forward(inputs)\n",
        "        return self.output_layer.feed_forward(hidden_layer_outputs)\n",
        "\n",
        "    # Uses online learning, ie updating the weights after each training case\n",
        "    def train(self, training_inputs, training_outputs):\n",
        "        self.feed_forward(training_inputs)\n",
        "\n",
        "        # 1. Output neuron deltas\n",
        "        pd_errors_wrt_output_neuron_total_net_input = [0] * len(self.output_layer.neurons)\n",
        "        for o in range(len(self.output_layer.neurons)):\n",
        "\n",
        "            # ∂E/∂zⱼ\n",
        "            pd_errors_wrt_output_neuron_total_net_input[o] = self.output_layer.neurons[o].calculate_pd_error_wrt_total_net_input(training_outputs[o])\n",
        "\n",
        "        # 2. Hidden neuron deltas\n",
        "        pd_errors_wrt_hidden_neuron_total_net_input = [0] * len(self.hidden_layer.neurons)\n",
        "        for h in range(len(self.hidden_layer.neurons)):\n",
        "\n",
        "            # We need to calculate the derivative of the error with respect to the output of each hidden layer neuron\n",
        "            # dE/dyⱼ = Σ ∂E/∂zⱼ * ∂z/∂yⱼ = Σ ∂E/∂zⱼ * wᵢⱼ\n",
        "            d_error_wrt_hidden_neuron_output = 0\n",
        "            for o in range(len(self.output_layer.neurons)):\n",
        "                d_error_wrt_hidden_neuron_output += pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]\n",
        "\n",
        "            # ∂E/∂zⱼ = dE/dyⱼ * ∂zⱼ/∂\n",
        "            pd_errors_wrt_hidden_neuron_total_net_input[h] = d_error_wrt_hidden_neuron_output * self.hidden_layer.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
        "\n",
        "        # 3. Update output neuron weights\n",
        "        for o in range(len(self.output_layer.neurons)):\n",
        "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
        "\n",
        "                # ∂Eⱼ/∂wᵢⱼ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢⱼ\n",
        "                pd_error_wrt_weight = pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].calculate_pd_total_net_input_wrt_weight(w_ho)\n",
        "\n",
        "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
        "                self.output_layer.neurons[o].weights[w_ho] -= self.LEARNING_RATE * pd_error_wrt_weight\n",
        "\n",
        "        # 4. Update hidden neuron weights\n",
        "        for h in range(len(self.hidden_layer.neurons)):\n",
        "            for w_ih in range(len(self.hidden_layer.neurons[h].weights)):\n",
        "\n",
        "                # ∂Eⱼ/∂wᵢ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢ\n",
        "                pd_error_wrt_weight = pd_errors_wrt_hidden_neuron_total_net_input[h] * self.hidden_layer.neurons[h].calculate_pd_total_net_input_wrt_weight(w_ih)\n",
        "\n",
        "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
        "                self.hidden_layer.neurons[h].weights[w_ih] -= self.LEARNING_RATE * pd_error_wrt_weight\n",
        "\n",
        "    def calculate_total_error(self, training_sets):\n",
        "        total_error = 0\n",
        "        for t in range(len(training_sets)):\n",
        "            training_inputs, training_outputs = training_sets[t]\n",
        "            self.feed_forward(training_inputs)\n",
        "            for o in range(len(training_outputs)):\n",
        "                total_error += self.output_layer.neurons[o].calculate_error(training_outputs[o])\n",
        "        return total_error\n",
        "\n",
        "class NeuronLayer:\n",
        "    def __init__(self, num_neurons, bias):\n",
        "\n",
        "        # Every neuron in a layer shares the same bias\n",
        "        self.bias = bias if bias else random.random()\n",
        "\n",
        "        self.neurons = []\n",
        "        for i in range(num_neurons):\n",
        "            self.neurons.append(Neuron(self.bias))\n",
        "\n",
        "    def inspect(self):\n",
        "        print('Neurons:', len(self.neurons))\n",
        "        for n in range(len(self.neurons)):\n",
        "            print(' Neuron', n)\n",
        "            for w in range(len(self.neurons[n].weights)):\n",
        "                print('  Weight:', self.neurons[n].weights[w])\n",
        "            print('  Bias:', self.bias)\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        outputs = []\n",
        "        for neuron in self.neurons:\n",
        "            outputs.append(neuron.calculate_output(inputs))\n",
        "        return outputs\n",
        "\n",
        "    def get_outputs(self):\n",
        "        outputs = []\n",
        "        for neuron in self.neurons:\n",
        "            outputs.append(neuron.output)\n",
        "        return outputs\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self, bias):\n",
        "        self.bias = bias\n",
        "        self.weights = []\n",
        "\n",
        "    def calculate_output(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = self.squash(self.calculate_total_net_input())\n",
        "        return self.output\n",
        "\n",
        "    def calculate_total_net_input(self):\n",
        "        total = 0\n",
        "        for i in range(len(self.inputs)):\n",
        "            total += self.inputs[i] * self.weights[i]\n",
        "        return total + self.bias\n",
        "\n",
        "    # Apply the logistic function to squash the output of the neuron\n",
        "    # The result is sometimes referred to as 'net' [2] or 'net' [1]\n",
        "    def squash(self, total_net_input):\n",
        "        return 1 / (1 + math.exp(-total_net_input))\n",
        "\n",
        "    # Determine how much the neuron's total input has to change to move closer to the expected output\n",
        "    #\n",
        "    # Now that we have the partial derivative of the error with respect to the output (∂E/∂yⱼ) and\n",
        "    # the derivative of the output with respect to the total net input (dyⱼ/dzⱼ) we can calculate\n",
        "    # the partial derivative of the error with respect to the total net input.\n",
        "    # This value is also known as the delta (δ) [1]\n",
        "    # δ = ∂E/∂zⱼ = ∂E/∂yⱼ * dyⱼ/dzⱼ\n",
        "    #\n",
        "    def calculate_pd_error_wrt_total_net_input(self, target_output):\n",
        "        return self.calculate_pd_error_wrt_output(target_output) * self.calculate_pd_total_net_input_wrt_input();\n",
        "\n",
        "    # The error for each neuron is calculated by the Mean Square Error method:\n",
        "    def calculate_error(self, target_output):\n",
        "        return 0.5 * (target_output - self.output) ** 2\n",
        "\n",
        "    # The partial derivate of the error with respect to actual output then is calculated by:\n",
        "    # = 2 * 0.5 * (target output - actual output) ^ (2 - 1) * -1\n",
        "    # = -(target output - actual output)\n",
        "    #\n",
        "    # The Wikipedia article on backpropagation [1] simplifies to the following, but most other learning material does not [2]\n",
        "    # = actual output - target output\n",
        "    #\n",
        "    # Alternative, you can use (target - output), but then need to add it during backpropagation [3]\n",
        "    #\n",
        "    # Note that the actual output of the output neuron is often written as yⱼ and target output as tⱼ so:\n",
        "    # = ∂E/∂yⱼ = -(tⱼ - yⱼ)\n",
        "    def calculate_pd_error_wrt_output(self, target_output):\n",
        "        return -(target_output - self.output)\n",
        "\n",
        "    # The total net input into the neuron is squashed using logistic function to calculate the neuron's output:\n",
        "    # yⱼ = φ = 1 / (1 + e^(-zⱼ))\n",
        "    # Note that where ⱼ represents the output of the neurons in whatever layer we're looking at and ᵢ represents the layer below it\n",
        "    #\n",
        "    # The derivative (not partial derivative since there is only one variable) of the output then is:\n",
        "    # dyⱼ/dzⱼ = yⱼ * (1 - yⱼ)\n",
        "    def calculate_pd_total_net_input_wrt_input(self):\n",
        "        return self.output * (1 - self.output)\n",
        "\n",
        "    # The total net input is the weighted sum of all the inputs to the neuron and their respective weights:\n",
        "    # = zⱼ = netⱼ = x₁w₁ + x₂w₂ ...\n",
        "    #\n",
        "    # The partial derivative of the total net input with respective to a given weight (with everything else held constant) then is:\n",
        "    # = ∂zⱼ/∂wᵢ = some constant + 1 * xᵢw₁^(1-0) + some constant ... = xᵢ\n",
        "    def calculate_pd_total_net_input_wrt_weight(self, index):\n",
        "        return self.inputs[index]\n",
        "def plots(ErrorRate):\n",
        "  if not ErrorRate :\n",
        "    return 'null'\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))  \n",
        "  plt.grid()\n",
        "  ErrorRate=np.asarray(ErrorRate)\n",
        "  plt.plot(ErrorRate,c='r',label='GrediantError')\n",
        "  plt.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
        "  plt.show()\n",
        "###\n",
        "\n",
        "# Blog post example:\n",
        "\n",
        "nn = NeuralNetwork(2, 2, 2, hidden_layer_weights=[0.15, 0.2, 0.25, 0.3], hidden_layer_bias=0.35, output_layer_weights=[0.4, 0.45, 0.5, 0.55], output_layer_bias=0.6)\n",
        "for i in range(100):\n",
        "    nn.train([0.05, 0.1], [0.01, 0.99])\n",
        "    ErrorRate= round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9)\n",
        "    print(i,ErrorRate)\n",
        "    Error.append(ErrorRate)\n",
        "plots(Error)\n",
        "# XOR example:\n",
        "\n",
        "# training_sets = [\n",
        "#     [[0, 0], [0]],\n",
        "#     [[0, 1], [1]],\n",
        "#     [[1, 0], [1]],\n",
        "#     [[1, 1], [0]]\n",
        "# ]\n",
        "\n",
        "# nn = NeuralNetwork(len(training_sets[0][0]), 5, len(training_sets[0][1]))\n",
        "# for i in range(10000):\n",
        "#     training_inputs, training_outputs = random.choice(training_sets)\n",
        "#     nn.train(training_inputs, training_outputs)\n",
        "#     print(i, nn.calculate_total_error(training_sets))"
      ]
    }
  ]
}